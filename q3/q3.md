## Post
æŒ‡æ ‡ | ğŸ± Cats â€“ Logistic | ğŸ± Cats â€“ RF | ğŸ¶ Dogs â€“ Logistic | ğŸ¶ Dogs â€“ RF
Accuracy | 0.82 | 0.83 âœ… | 0.80 | 0.84 âœ…
ROC-AUC | 0.88 | 0.89 âœ… | 0.85 | 0.91 âœ…
Precision (Class 1) | 0.78 | 0.82 âœ… | 0.71 | 0.83 âœ…
Recall (Class 1) | 0.63 | 0.64 âœ… | 0.66 | 0.66 (=)
F1-score (Class 1) | 0.69 | 0.72 âœ… | 0.69 | 0.74 âœ…
Confusion Matrix FN | 129 | 124 | 109 | =
Top Feature | contains_adopt_keywords | title_length | contains_adopt_keywords | title_length

éšæœºæ£®æ—åœ¨æ‰€æœ‰ä¸»è¦æŒ‡æ ‡ä¸Šå‡ç•¥ä¼˜äºé€»è¾‘å›å½’ï¼Œç‰¹åˆ«æ˜¯ï¼š

Recall æ²¡æœ‰ä¸‹é™ï¼Œä½† Precision æ˜æ˜¾ä¸Šå‡

AUC å‡æå‡ï¼Œè¡¨ç¤ºå¯¹é«˜äº’åŠ¨å¸–æ›´èƒ½â€œçœ‹å¾—å‡†â€

We compared Logistic Regression and Random Forest classifiers for predicting high-engagement Reddit posts in pet adoption communities. Across both cat and dog posts, the Random Forest model outperformed the linear model in all key metrics, including ROC-AUC (Cats: 0.89 vs 0.88, Dogs: 0.91 vs 0.85), precision, and F1-score. Notably, recall remained stable while precision improved significantly for dog postsâ€”from 0.71 to 0.83â€”indicating a stronger ability to avoid false positives. Feature importance analysis revealed that while contains_adopt_keywords was highly valued in logistic models, Random Forest prioritized more structural elements like title_length, num_words, and urgency-related verbs like rescue or need.

Yes â€” we can reliably predict whether a pet adoption post will have high engagement using a combination of linguistic style features and keyword-based TF-IDF vectors.

å…·ä½“è¯´æ˜å¦‚ä¸‹ï¼š

Logistic Regression AUC è¾¾åˆ° 0.88ï¼ˆçŒ«ï¼‰ã€0.85ï¼ˆç‹—ï¼‰

Random Forest AUC è¾¾åˆ° 0.89ï¼ˆçŒ«ï¼‰ã€0.91ï¼ˆç‹—ï¼‰

ç‰¹å¾å¦‚ title_length, num_verbs, contains_adopt_keywords æ˜¾è‘—æå‡é¢„æµ‹èƒ½åŠ›

Recall è¡¨ç°ç¨³å¥ï¼ŒPrecision æ˜¾è‘—æå‡

æ¨¡å‹å¯è¢«éƒ¨ç½²ä¸ºæ‰“åˆ†ç³»ç»Ÿæˆ–é£æ ¼å»ºè®®å¼•æ“